# -*- coding: utf-8 -*-
"""ela_xaralampe_mou_eisai_ok_me_touto_to_onoma.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/157AH7OY4i6W_Jz_4dCrP0xJlTHoaSdbw

#<center>**Άσκηση 1. Επιβλεπόμενη Μάθηση: Ταξινόμηση. Μελέτη datasets του UCI Machine Learning Repository**</center>

# I. Στοιχεία ομάδας 19

1.   Δαμιανός Παππάς       , ΑΜ: 03116608
2.   Χαράλαμπος Ρωσσίδης, ΑΜ: 03116701
3.   Νεκτάριος Ματσάγκος, ΑΜ: 03116709
"""

!pip install --upgrade pip 
!pip install scikit-learn --upgrade 
!pip install numpy --upgrade 
!pip install pandas --upgrade
!pip install --upgrade matplotlib

"""# II. Βασικές πληροφορίες

###1.Σύντομη παρουσίαση του dataset (τι περιγράφει).

The purpose is to classify a given silhouette as one of four types of vehicle, using a set of features extracted from the silhouette

### *2. Αριθμός δειγμάτων και χαρακτηριστικών, είδος χαρακτηριστικών. Υπάρχουν μη διατεταγμένα χαρακτηριστικά και ποια είναι αυτά;*
"""

import pandas as pd
data= pd.read_csv("all.csv",delim_whitespace=True,header=None)
data

import numpy as np
labels = data.iloc[:, 18]
labels

"""- Ο αριθμός δειγμάτων είναι 846, τα χαρακτηριστικά τους είναι 18 και το είδος τους είναι object. Δεν υπάρχουν μη διατεταγμένα χαρακτηριστικά.

### *3. Υπάρχουν επικεφαλίδες; Αρίθμηση γραμμών;*

- Δεν υπάρχουν επικεφαλίδες ούτε αρίθμηση γραμμών.
"""

features = data.iloc[:, 0:18]
features

"""### *4. Ποιες είναι οι ετικέτες των κλάσεων και σε ποια κολώνα βρίσκονται;*

- Οι ετικέτες των κλάσεων είναι 4 και είναι οι εξής: Opel, Saab, Van και Bus. Βρίσκονται στη κολώνα με αριθμό 18.

### *5. Χρειάστηκε να κάνετε μετατροπές στα αρχεία text και ποιες?*

- Δεν υπάρχει αρίθμηση στηλών και γραμμών, ούτε επικεφαλίδες άρα δεν χρειάζεται να κάνουμε μετατροπές στο αρχείο.

### *6. Υπάρχουν απουσιάζουσες τιμές; Πόσα είναι τα δείγματα με απουσιάζουσες τιμές και ποιο το ποσοστό τους επί του συνόλου;*
"""

features.isnull().values.any()

"""- Όχι δεν υπάρχουν απουσιάζουσες τιμές

### *7. Ποιος είναι ο αριθμός των κλάσεων και τα ποσοστά δειγμάτων τους επί του συνόλου; Αν θεωρήσουμε ότι ένα dataset είναι μη ισορροπημένο αν μια οποιαδήποτε κλάση είναι 1.5 φορά πιο συχνή από κάποια άλλη (60%-40% σε binary datasets) εκτιμήστε την ισορροπία του dataset.*
"""

frequencies = pd.value_counts(labels)
print("Συχνότητα εμφάνισης των δειγμάτων της κάθε κλάσης:")
print(frequencies)

print("Ποσοστό 'bus':", frequencies[0]/len(labels)*100, '%')
print("Ποσοστό 'saab':", frequencies[1]/len(labels)*100, '%')
print("Ποσοστό 'opel':", frequencies[2]/len(labels)*100, '%')
print("Ποσοστό 'van':", frequencies[3]/len(labels)*100, '%')

"""### *8. Διαχωρίστε σε train και test set. Εάν υπάρχουν απουσιάζουσες τιμές και μη διατεταγμένα χαρακτηριστικά διαχειριστείτε τα και αιτιολογήστε τις επιλογές σας.*"""

from sklearn.model_selection import train_test_split
features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.20)

"""- Όπως δείξαμε και πιο πάνω δεν υπάρχουν απουσιάζουσες τιμές και μη διατεταγμένα χαρακτηριστικά.

# III. Baseline Classification

###1. Διαχειριστείτε τυχόν απουσιάζουσες τιμές. Εκπαιδεύστε στο train τους classifiers με default τιμές (απλή αρχικοποίηση). Κάντε εκτίμηση στο test set (μαζί με τους dummy) και τυπώστε για κάθε estimator: confusion matrix, f1-micro average και f1-macro average.
"""

from sklearn.dummy import DummyClassifier
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import f1_score
import timeit

pred={}
micro={}
macro={}
fit_time={}
pred_time={}

dc_uniform = DummyClassifier(strategy="uniform")
dc_most_frequent = DummyClassifier(strategy="most_frequent")
dc_stratified = DummyClassifier(strategy="stratified")
start = timeit.default_timer()
model=dc_uniform.fit(features_train, labels_train)
stop = timeit.default_timer()
fit_time['uniform']= stop - start
start = timeit.default_timer()
pred["uniform"]= dc_uniform.predict(features_test)
stop = timeit.default_timer()
pred_time['uniform']= stop - start
cnf_matrix = confusion_matrix(labels_test, pred["uniform"])
print("UNIFORM")
print(classification_report(labels_test, pred["uniform"]))
print(cnf_matrix,"\n")



avg=f1_score(labels_test,pred["uniform"], average='micro')
micro["uniform"]=avg
avg=f1_score(labels_test,pred["uniform"], average='macro')
macro["uniform"]=avg

start = timeit.default_timer()
model=dc_most_frequent.fit(features_train, labels_train)
stop = timeit.default_timer()
fit_time['most frequent']= stop - start
start = timeit.default_timer()
pred["most_frequent"]= dc_most_frequent.predict(features_test)
stop = timeit.default_timer()
pred_time['most frequent']= stop - start
cnf_matrix = confusion_matrix(labels_test,pred["most_frequent"])
print("MOST FREQUENT")
print(classification_report(labels_test, pred["most_frequent"]))
print(cnf_matrix,"\n")


avg=f1_score(labels_test,pred["most_frequent"], average='micro')
micro["most_frequent"]=avg
avg=f1_score(labels_test,pred["most_frequent"], average='macro')
macro["most_frequent"]=avg


start = timeit.default_timer()
model=dc_stratified.fit(features_train, labels_train)
stop = timeit.default_timer()
fit_time['stratified']= stop - start
start = timeit.default_timer()
pred["stratified"]= dc_stratified.predict(features_test)
stop = timeit.default_timer()
pred_time['stratified']= stop - start
cnf_matrix = confusion_matrix(labels_test, pred["stratified"])
print("STRATIFIED")
print(classification_report(labels_test, pred["stratified"]))
print(cnf_matrix)
avg=f1_score(labels_test,pred["stratified"], average='micro')
micro["stratified"]=avg
avg=f1_score(labels_test,pred["stratified"], average='macro')
macro["stratified"]=avg

from sklearn.naive_bayes import GaussianNB

gnb = GaussianNB()
start = timeit.default_timer()
model = gnb.fit(features_train, labels_train)
stop = timeit.default_timer()
fit_time['gnb']= stop - start
start = timeit.default_timer()
pred["gnb"] = gnb.predict(features_test)
stop = timeit.default_timer()
pred_time['gnb']= stop - start
cnf_matrix = confusion_matrix(labels_test,pred["gnb"])
print("Gaussian Naive Bayes")
print(cnf_matrix,"\n")
print(classification_report(labels_test, pred["gnb"]))

avg=f1_score(labels_test,pred["gnb"], average='micro')
micro["gnb"]=avg
avg=f1_score(labels_test,pred["gnb"], average='macro')
macro["gnb"]=avg

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=9)
start = timeit.default_timer()
knn.fit(features_train, labels_train)
stop = timeit.default_timer()
fit_time['knn']= stop - start
start = timeit.default_timer()
pred["knn"] = knn.predict(features_test)
stop = timeit.default_timer()
pred_time['knn']= stop - start
cnf_matrix = confusion_matrix(labels_test, pred["knn"])
print("kNN")
print(cnf_matrix, "\n")
print(classification_report(labels_test, pred["knn"]))

avg=f1_score(labels_test,pred["knn"], average='micro')
micro["knn"]=avg
avg=f1_score(labels_test,pred["knn"], average='macro')
macro["knn"]=avg

"""### *2. Για κάθε averaged metric, εκτυπώστε bar plot συγκρισης με τις τιμές του συγκεκριμένου f1 για όλους τους classifiers.*"""

import matplotlib.pyplot as plt

data = {'uniform': micro['uniform'], 'stratified': micro['stratified'], 'most frequent': micro['most_frequent'],'Gnb': micro['gnb'],'knn': micro['knn']}
names = list(data.keys())
values = list(data.values())

#tick_label does the some work as plt.xticks()
plt.bar(range(len(data)),values,tick_label=names)
plt.savefig('bar.png')
plt.title("f1 score for micro average", fontsize = 18)
plt.xlabel("$Classifiers$", fontsize = 16)
plt.ylabel("$f1\ score$", fontsize = 16)
plt.show()

data = {'uniform': macro['uniform'], 'stratified': macro['stratified'], 'most frequent': macro['most_frequent'],'Gnb': macro['gnb'],'knn': macro['knn']}
names = list(data.keys())
values = list(data.values())

#tick_label does the some work as plt.xticks()
plt.bar(range(len(data)),values,tick_label=names)
plt.savefig('bar.png')
plt.title("f1 score for macro average", fontsize = 18)
plt.xlabel("$Classifiers$", fontsize = 16)
plt.ylabel("$f1\ score$", fontsize = 16)
plt.show()

"""### *3.Σχολιάστε τα αποτελέσματα των plots και των τιμών precision, recall, f1 των πινάκων σύγχυσης.*

Αυτό που παρατηρούμε είναι ότι ο knn clasifier είναι αυτός με τη περισσότερη ακρίβεια με σημαντική διαφορά από το δεύτερο clasifier που είναι ο Gnb. Αυτή η διαφορά φαίνεται να είναι πιο μεγάλη στο f1_macro_average και το f1_micro_average. Όπως ήταν αναμενόμενο οι 3 dummy clasifiers έχουν μικρό ποσοστό επιτυχίας ενώ ο Gaussian Naive Bayes και ο knn οι οποίοι είναι μαθηματικές μέθοδοι, το ποσοστό επιτυχίας είναι σημαντικά μεγαλύτερο.

# IV. Βελτιστοποίηση ταξινομητών

### *1. Για κάθε ταξινομητή βελτιστοποιήστε την απόδοσή του στο training set μέσω της διαδικασίας προεπεξεργασίας και εύρεσης βέλτιστων υπερπαραμέτρων (δεν έχουν όλοι οι ταξινομητές υπερπαραμέτρους). Κάντε εκτίμηση στο test set (μαζί με τους dummy) και τυπώστε για κάθε estimator: confusion matrix, f1-micro average και f1-macro average.*
"""

from sklearn.model_selection import cross_val_score

myList = list(range(1,50))
neighbors = list(filter(lambda x: x % 2 != 0, myList))
cv_scores = []
for k in neighbors:
    knn = KNeighborsClassifier(n_neighbors=k)
    scores = cross_val_score(knn, features_train, labels_train, cv=10)
    cv_scores.append(scores.mean())

import matplotlib.pyplot as plt

mean_error = [1 - x for x in cv_scores]
plt.plot(neighbors, mean_error)
plt.xlabel('Number of Neighbors K')
plt.ylabel('Misclassification Error')
plt.show()
optimal_k = neighbors[mean_error.index(min(mean_error))]
print("Καλύτερο κ = %d" % optimal_k)

knn = KNeighborsClassifier(n_neighbors = optimal_k)
start = timeit.default_timer()
knn.fit(features_train, labels_train)
stop = timeit.default_timer()
fit_time['best knn']= stop - start
start = timeit.default_timer()
pred["best knn"] = knn.predict(features_test)
stop = timeit.default_timer()
pred_time['best knn']= stop - start

cnf_matrix = confusion_matrix(labels_test, pred["best knn"])
print(cnf_matrix, "\n")
print(classification_report(labels_test, pred["best knn"]))

avg=f1_score(labels_test,pred["best knn"], average='micro')
micro["best knn"]=avg
avg=f1_score(labels_test,pred["best knn"], average='macro')
macro["best knn"]=avg

dc_uniform = DummyClassifier(strategy="uniform")
dc_most_frequent = DummyClassifier(strategy="most_frequent")
dc_stratified = DummyClassifier(strategy="stratified")

model=dc_uniform.fit(features_train, labels_train)
pred["uniform"]= dc_uniform.predict(features_test)
cnf_matrix = confusion_matrix(labels_test, pred["uniform"])
print("UNIFORM")
print(classification_report(labels_test, pred["uniform"]))
print(cnf_matrix,"\n")



avg=f1_score(labels_test,pred["uniform"], average='micro')
micro["uniform"]=avg
avg=f1_score(labels_test,pred["uniform"], average='macro')
macro["uniform"]=avg


model=dc_most_frequent.fit(features_train, labels_train)
pred["most_frequent"]= dc_most_frequent.predict(features_test)
cnf_matrix = confusion_matrix(labels_test,pred["most_frequent"])
print("MOST FREQUENT")
print(classification_report(labels_test, pred["most_frequent"]))
print(cnf_matrix,"\n")


avg=f1_score(labels_test,pred["most_frequent"], average='micro')
micro["most_frequent"]=avg
avg=f1_score(labels_test,pred["most_frequent"], average='macro')
macro["most_frequent"]=avg



model=dc_stratified.fit(features_train, labels_train)
pred["stratified"]= dc_stratified.predict(features_test)
cnf_matrix = confusion_matrix(labels_test, pred["stratified"])
print("STRATIFIED")
print(classification_report(labels_test, pred["stratified"]))
print(cnf_matrix)
avg=f1_score(labels_test,pred["stratified"], average='micro')
micro["stratified"]=avg
avg=f1_score(labels_test,pred["stratified"], average='macro')
macro["stratified"]=avg

from sklearn.naive_bayes import GaussianNB

gnb = GaussianNB()
model = gnb.fit(features_train, labels_train)
pred["gnb"] = gnb.predict(features_test)
cnf_matrix = confusion_matrix(labels_test,pred["gnb"])
print("Gaussian Naive Bayes")
print(cnf_matrix,"\n")
print(classification_report(labels_test, pred["gnb"]))

avg=f1_score(labels_test,pred["gnb"], average='micro')
micro["gnb"]=avg
avg=f1_score(labels_test,pred["gnb"], average='macro')
macro["gnb"]=avg

"""### *2. Για το τελικό fit του κάθε ταξινομητή στο σύνολο του training set και για το predict στο test set εκτυπώστε πίνακες με τους χρόνους εκτέλεσης.*"""

print("Μεταβολη Χρονου για fit και predict")
test_set_fit_time=[]
test_set_pred_time=[]
test_set_fit_time= fit_time['knn'], fit_time['gnb'], fit_time['stratified'],fit_time['most frequent'],fit_time['uniform'],fit_time['best knn']
test_set_pred_time=pred_time['knn'], pred_time['gnb'], pred_time['stratified'],pred_time['most frequent'],pred_time['uniform'],pred_time['best knn']
test_times = [test_set_fit_time,test_set_pred_time]
pd.DataFrame(test_times, index=["Fitting Time", "Prediction Time"], columns = ["KNN", "GNB","STRATIFIED","MOST FREQUENT","UNIFORM","OPTIMIZED KNN"])

"""### *3. Για κάθε averaged metric, εκτυπώστε bar plot σύγκρισης με τις τιμές του συγκεκριμένου f1 για όλους τους classifiers.*"""

data = {'uniform': micro['uniform'], 'stratified': micro['stratified'], 'most frequent': micro['most_frequent'],'Gnb': micro['gnb'],'knn': micro['knn'],'best knn': micro['best knn']}
names = list(data.keys())
values = list(data.values())


plt.bar(range(len(data)),values,tick_label=names)
plt.savefig('bar.png')
plt.title("f1 score for micro average", fontsize = 18)
plt.xlabel("$Classifiers$", fontsize = 16)
plt.ylabel("$f1\ score$", fontsize = 16)
plt.xticks(rotation = 60, fontsize = 12)
plt.show()

data = {'uniform': macro['uniform'], 'stratified': macro['stratified'], 'most frequent': macro['most_frequent'],'Gnb': macro['gnb'],'knn': macro['knn'],'best knn':macro['best knn']}
names = list(data.keys())
values = list(data.values())


plt.bar(range(len(data)),values,tick_label=names)
plt.savefig('bar.png')
plt.title("f1 score for macro average", fontsize = 18)
plt.xlabel("$Classifiers$", fontsize = 16)
plt.ylabel("$f1\ score$", fontsize = 16)
plt.xticks(rotation = 60, fontsize = 12)
plt.show()

"""### *4. Τυπώστε πίνακα με τη μεταβολή της επίδοσης των ταξινομητών πριν και μετά τη βελτιστοποίησή τους.*

"""

print("kNN")
f1_progress = [[macro["knn"], micro["knn"]],[macro["best knn"], micro["best knn"]]]
pd.DataFrame(f1_progress, columns=["f1 macro score ", "f1 micro score"], index = ["before", "after"])

f1_progress_before = [macro["knn"], micro["knn"]]
f1_progress_after=[macro["best knn"], micro["best knn"]]
res = tuple(map(lambda i, j: i - j, f1_progress_after, f1_progress_before)) 
pd.DataFrame(res, index=["f1_progress_macro", "f1_progress_micro"], columns = ["kNN Improvement"])

"""### *5. Σχολιάστε τα αποτελέσματα των plots και των τιμών precision, recall, f1 των πινάκων σύγχυσης, τη μεταβολή της απόδοσης και τους χρόνους εκτέλεσης.*

Όσο αφορά τα plots παρατηρούμε τη βελτίωση του knn σε σύγκριση με τα προηγούμενα plots και για τα δύο metrics (micro και macro). Οι άλλοι ταξινομητές(dummies) βγάζουν τα ίδια αποτελέσματα όπως είναι αναμενόμενο.
Όσο αφορά τις τιμές precision, recall και f1 των πινάκων σύγχισης παρατηρούμε ότι και αυτές βελτιώνονται. Πιο συγκεκριμένα τώρα έχουμε λιγότερα false negatives και false positives άρα έχουμε καλύτερο precision και recall και για τις δύο κλάσεις. Παρατηρούμε βελτίωση στην απόδοση του knn ταξινομητή της τάξης του 5%. Επίσης βλέπουμε ότι ο χρόνος εκπαίδευσης και πρόβλεψης είναι πολύ μικροί (της τάξης των ms). Αυτό οφείλεται στο ότι τα δεδομένα είναι πολύ λίγα ήδη από το στάδιο της προεπεξεργασίας.
Γενικά τα δύο averaged metrics (micro και macro) βγάζουν πολύ κοντινά αποτελέσματα με πολύ μικρές διαφορές μεταξύ τους, ουσιαστικά ασήμαντες.
"""